{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Naomi Baes and Chat GPT\n",
    "\n",
    "**Aim**: Get contexts to compute breadth measure\n",
    "\n",
    "**Function:** This script filters lines from input files based on specified terms found in the first column, then generates samples from the filtered lines for each 5-year interval, saving them in an output directory.\n",
    "\n",
    "- Sampling strategy: Generate up to 50 random sentences 10 times from target_term filtered lines for further analysis.\n",
    "- Output example for generate_interval_samples(): mental_illness.sentences.psych.1970-1974.1; [...].2, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter contexts and get sample sentence contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation completed.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import os\n",
    "import random\n",
    "\n",
    "def filter_lines(input_file, term, output_file):\n",
    "    term_pattern = re.compile(rf\"(\\b{term}\\b)\", re.IGNORECASE)\n",
    "    with open(input_file, 'r', encoding='utf-8') as infile, open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        for line in infile:\n",
    "            first_column = line.split(\" ||||| \")[0]  # Extract the first column\n",
    "            if term_pattern.search(first_column):  # Search for the term in the first column\n",
    "                outfile.write(line)  # Write the entire line to the output file\n",
    "\n",
    "def generate_samples(input_file, class_name, corpus):\n",
    "    output_dir = \"output/5-year.cosine\"\n",
    "    input_dir = \"input\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    os.makedirs(input_dir, exist_ok=True)\n",
    "    context_file = f\"{class_name}.context.{corpus}\"\n",
    "    pattern_year = re.compile(r'\\|\\|\\|\\| (\\d{4}) \\|\\|\\|\\|')\n",
    "    pattern_mental = re.compile(r'([^.]*?\\b' + re.escape(class_name) + r'\\b[^.]*\\.)')\n",
    "    \n",
    "    # Filter lines based on the term in the first column\n",
    "    filter_lines(input_file, class_name, f\"{input_dir}/{context_file}\")\n",
    "    \n",
    "    # Read filtered lines from context file\n",
    "    with open(f\"{input_dir}/{context_file}\", \"r\", encoding='utf-8') as file:\n",
    "        filtered_lines = [line.strip() for line in file]\n",
    "    \n",
    "    # Generate samples for each 5-year interval\n",
    "    for interval_start in range(1970, 2020, 5):\n",
    "        generate_interval_samples(interval_start, filtered_lines, output_dir, class_name, corpus, pattern_year, pattern_mental)\n",
    "\n",
    "def generate_interval_samples(interval_start, filtered_lines, output_dir, class_name, corpus, pattern_year, pattern_mental):\n",
    "    for i in range(1, 11):\n",
    "        samples = []\n",
    "        for line in filtered_lines:\n",
    "            match = pattern_year.search(line)\n",
    "            if match:\n",
    "                year = int(match.group(1))\n",
    "                if interval_start <= year < interval_start + 5:\n",
    "                    match = pattern_mental.search(line)\n",
    "                    if match:\n",
    "                        samples.append(match.group(1).strip())\n",
    "        samples = random.sample(samples, min(50, len(samples)))\n",
    "        with open(f\"{output_dir}/{class_name}.{interval_start}-{interval_start+4}.{corpus}.{i}\", \"w\") as output_file:\n",
    "            output_file.write(\"\\n\".join(samples))\n",
    "\n",
    "# Define input file paths\n",
    "input_files = {\n",
    "    \"psych\": \"C:/Users/naomi/OneDrive/COMP80004_PhDResearch/RESEARCH/DATA/CORPORA/Psychology/abstract_year_journal.csv.mental\",\n",
    "    \"cohacoca\": \"C:/Users/naomi/OneDrive/COMP80004_PhDResearch/RESEARCH/DATA/CORPORA/COHACOCA/coha.coca.cleaned2.mental\"\n",
    "}\n",
    "\n",
    "# Define terms to search for\n",
    "terms = [\"mental_illness\", \"mental_health\", \"perception\"]\n",
    "\n",
    "# Iterate over each corpus and term to generate samples\n",
    "for corpus, input_file in input_files.items():\n",
    "    for term in terms:\n",
    "        generate_samples(input_file, term, corpus)\n",
    "\n",
    "print(\"Generation completed.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
